# Questions and Answers {.unnumbered}

::: {.callout-tip}

## What are the relationships between linear equations, vectors, matrices, and linear combinations?

This explanation is based on how the textbook brings up these concepts.

At first, the textbook introduces matrices using linear equations by writing the coefficients line by line. Therefore, a matrix can be a way of representing a system of linear equations. Then, an alternative way to represent the same system of linear equations, vector equations, are introduced. As a recap, a vector equation is defined as follows:
$$x_1\mathbf{v}_1+\dots+x_n\mathbf{v}_n=\mathbf{b}.$$
To be specific, the vectors discussed so far are column vectors. Subsequently, the linear combination of vectors are defined as $c_1\mathbf{v}_1+\dots+c_n\mathbf{v}_n$. All linear combinations of the set of vectors are denoted as $\text{span}\{\mathbf{v}_1,\dots,\mathbf{v}_n\}=\{c_1\mathbf{v}_1+\dots+c_n\mathbf{v_n}\mid c_1,\dots,c_n\in \mathbb{R}\}$.

Afterward, the multiplication of a matrix and a **column** vector is defined:
$$\begin{bmatrix}\mathbf{v}_1 & \cdots & \mathbf{v}_n\end{bmatrix}\begin{bmatrix}x_1 \\ \vdots \\ x_n\end{bmatrix}=x_1\mathbf{v}_1+\dots+x_n\mathbf{v}_n.$$
Observably, the result of the multiplication is a linear combination of $\mathbf{v}_1,\dots,\mathbf{v}_n$ using $x_1,\dots,x_n$ as the coefficients. Suppose $\mathbf{v}_1,\dots,\mathbf{v}_n\in\mathbb{R}^m$, then $\begin{bmatrix}\mathbf{v}_1 & \cdots & \mathbf{v}_n\end{bmatrix}$ is an $m\times n$ matrix. Thus, the previously introduced vector equation can be written as $A\mathbf{x}=\mathbf{b}$, where $A=\begin{bmatrix}\mathbf{v}_1 & \cdots & \mathbf{v}_n\end{bmatrix}$ and $\mathbf{x}=\begin{bmatrix}x_1 \\ \vdots \\ x_n\end{bmatrix}$.

Viewing the coefficients $c_1,\dots,c_n$ in linear combinations as the unknowns, finding a set of coefficients whose corresponding linear combination is $\mathbf{b}$ is equivalent to solving the vector equation $c_1\mathbf{v}_1+\dots+c_n\mathbf{v}_n=\mathbf{b}$, or $\begin{bmatrix}\mathbf{v}_1 & \cdots & \mathbf{v}_n\end{bmatrix}\begin{bmatrix}c_1\\\vdots\\c_n\end{bmatrix}=\mathbf{b}$, which all tie back to a set of linear equations. Later, the concept of linear independence is defined: $A\mathbf{x}=\mathbf{0}$ has only the trivial solution, which can be judged using the echelon forms of a matrix.
:::