# 1.7 Linear Independence {.unnumbered}

## Definition and Characterization

::: {#def-linearindependence}

## Linear Independence
An indexed set of vectors $\{\mathbf{v}_1,\dots,\mathbf{v}_n\}$ in $\mathbb{R}^m$ is said to be linearly independent if the vector equation
$$x_1\mathbf{v}_1+x_2\mathbf{v}_2+\dots+x_n\mathbf{v}_n=\mathbf{0}$$
has only the trivial solution ($\mathbf{x}=\mathbf{0}$). Otherwise, it is said to be linearly dependent.
:::

::: {#thm-thm1-7-7}

## Theorem 7: Characterization of Linearly Dependent Sets

An indexed set $S = \{\mathbf{v}_1, \dots, \mathbf{v}_n\}$ of two or more vectors is linearly dependent if and only if at least one of the vectors in $S$ is a linear combination of the others. In fact, if $S$ is linearly dependent and $\mathbf{v}_1 \neq \mathbf{0}$, then some $\mathbf{v}_j$ (with $j > 1$) is a linear combination of the preceding vectors, $\mathbf{v}_1,\dots,\mathbf{v}_{j-1}$.
:::

::: {.proof}

## Proof of [@thm-thm1-7-7]

Let "in fact" separate the theorem into two parts. Consider the first part.

1. If there is a vector that is a linear combination of the other vectors,
$$\mathbf{v}_i=c_1\mathbf{v}_1+\dots+c_{i-1}\mathbf{v}_{i-1}+c_{i+1}\mathbf{v}_{i+1}+\dots+c_n\mathbf{v}_n,$$
move the terms into one side:
$$c_1\mathbf{v}_1+\dots+c_{i-1}\mathbf{v}_{i-1}+(-1)\mathbf{v}_i+c_{i+1}\mathbf{v}_{i+1}+\dots+c_n\mathbf{v}_n=\mathbf{0}.$$
Thus, there is a nontrivial solution for $\mathbf{c}$, where $c_i=-1$, so the set is linearly dependent.

2. If the set is linearly dependent, the vector equation $c_1\mathbf{v}_1+\dots+c_n\mathbf{v}_n=\mathbf{0}$ has nontrivial solution of $\mathbf{c}$. There exists an index $i$ where $c_i \neq 0$. Move the $i$-th term to the left hand side and the other terms to the right hand side:
$$-c_i\mathbf{v}_i=c_1\mathbf{v}_1+\dots+c_{i-1}\mathbf{v}_{i-1}+c_{i+1}\mathbf{v}_{i+1}+\dots+c_n\mathbf{v}_n.$$
Divide both sides by $-c_i$:
$$\mathbf{v}_i=\frac{c_1}{-c_i}\mathbf{v}_1+\dots+\frac{c_{i-1}}{-c_i}\mathbf{v}_{i-1}+\frac{c_{i+1}}{-c_i}\mathbf{v}_{i+1}+\dots+\frac{c_n}{-c_i}\mathbf{v}_n.$$
Hence, $\mathbf{v}_i$ is a linear combination of the other vectors in the set.

We have now proved the first part of the theorem. Let's prove the second part by induction and contradiction.

If $\mathbf{v}_j = \mathbf{0}$ ($1 < j \leq n$), $\mathbf{v}_j$ can be expressed as $0\cdot\mathbf{v}_1+\dots+0\cdot\mathbf{v}_{j-1}$, so we only consider situations that, for all $1 \leq j \leq n$, $\mathbf{v}_j\neq\mathbf{0}$.

Let $A_k=\begin{bmatrix} \mathbf{v}_1 & \cdots & \mathbf{v}_k \end{bmatrix}$, where $1 \leq k \leq n$, so $A \in \mathbb{R}^{m \times k}$.

The reduced row echelon form (RREF) of $A_1$ is $\begin{bmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}$. If $\mathbf{v}_2$ is not a linear combination of $\mathbf{v}_1$, $\{\mathbf{v}_1, \mathbf{v}_2\}$ is linearly independent. Thus, the RREF of $A_2$ is $\begin{bmatrix} 1 & 0 \\ 0 & 1 \\ \vdots & \vdots \\ 0 & 0 \end{bmatrix}$. Similarly, the RREF of $A_3$ needs to be $\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ \vdots & \vdots & \vdots \\ 0 & 0 & 0 \end{bmatrix}$, since if there is no pivot position in the third column, the solution of $A_3\begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix}=\mathbf{0}$ can be written as $\begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix}=x_3\begin{bmatrix}u_1\\u_2\\1\end{bmatrix}$, where $x_3,u_1,u_2\in\mathbb{R}$. Thus, the RREF of $A_k$ must be in the form of $\begin{bmatrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 1 \\ \vdots & \vdots & \vdots & \vdots \\ 0 & 0 & 0 & 0 \end{bmatrix}$. When $k=n$, the matrix equation $A_n\mathbf{x}=\mathbf{0}$ has only the trivial solution because every column has a pivot position. Hence, $S$ is linearly independent, contradicting the stated condition that $S$ is linearly dependent.
:::

::: {.remark}

When the author first learned about linear independence, the characteristic (@thm-thm1-7-7), rather than the definition (@def-linearindependence), was taught first. That is, if none of the vectors in a set are a linear combination of the other vectors, the set is linearly independent. This characterization may more intuitively illustrates the name "linear independence" than the definition does, as every vector is "independent" of the other vectors.
:::

## Pivot Columns and Linear Independence

::: {#exr-t27}

## T27

How many pivot columns must a $7 \times 5$ matrix have if its columns are linearly independent?
:::

::: {#sol-t27}

## Solution to [@exr-t27]

Recall the definition of linear indenpendence: $A\mathbf{x}=\mathbf{0}$ has only the trivial solution ($\mathbf{x}=\mathbf{0}$). There must be 5 pivot columns in $A$'s row echelon form (REF). Otherwise, the free variable(s) will produce solutions other than $\mathbf{0}$.

If we generalize the situation to $A \in \mathbb{R}^{m \times n}$, $n$ pivot columns are required to avoid free variables. Therefore, the columns of $A$ are necessarily linearly dependent when $n > m$, as there are no enough rows to generate $n$ pivot columns (Theorem 8).
:::

::: {.remark}

What if there are columns without a pivot position?

Let the $k$-th column be one of those columns. Then, $x_k$ is a free variable. According to the proof of [@thm-thm1-7-7], $\mathbf{v}_k \in \text{Span}\{\mathbf{v}_1,\dots,\mathbf{v}_{k-1}\}$. In addition, we can observe the solution of the matrix equation $A\mathbf{x}=\mathbf{0}$, $\mathbf{x}=x_k\mathbf{u}+x_{k_1}\mathbf{u}_1+\dots+x_{k_t}\mathbf{u}_t$, where $\mathbf{u},\mathbf{u}_1,\dots,\mathbf{u}_t$ are the vectors obtained from the RREF and $x_{k_1},\dots,x_{k_t}$ are other free variables. Set $x_{k_1},\dots,x_{k_t}$ equal to zero:
$$\mathbf{x}=x_k\mathbf{u}.$$
Substitute this into the vector equation, $x_1\mathbf{v}_1+\dots+x_n\mathbf{v}_n=\mathbf{0}$:
$$x_k u_1\mathbf{v}_1+\dots+x_k u_k\mathbf{v}_k+\dots+x_k u_n\mathbf{v}_n=\mathbf{0}.$$
Since $x_k$ is a free variable, we can divide the equation by $x_k$ if $x_k \neq 0$. Then, separate the $k$-th term to one side ($u_k=1$):
$$\mathbf{v}_k=(-u_1)\mathbf{v}_1+\dots+(-u_n)\mathbf{v}_n.$$
Since the matrix has been simplified to its RREF, $u_{k+1},\dots,u_n$ all equal zero. Then,
$$\mathbf{v}_k=(-u_1)\mathbf{v}_1+\dots+(-u_{k-1})\mathbf{v}_{k-1}.$$
Thus, the $k$-th column of the RREF exactly shows the coefficients of how it can be written as a linear combination of the preceding vectors.
:::

::: {#exr-1-7-28}

## T28

How many pivot columns must a $5 \times 7$ matrix have if its columns span $\mathbb{R}^5$?
:::

::: {#sol-1-7-28}

## Solution to [@sol-1-7-28]

That the vectors span $\mathbb{R}^5$ means that, for all $\mathbf{b} \in \mathbb{R}^5$, $\mathbf{b}$ can be expressed as a linear combination of the vectors. That is, the matrix equation $A\mathbf{x}=\mathbf{b}$ is consistent. Thus, each of the 5 rows of the REF of A must have a pivot position.

For $A \in \mathbb{R}^{m \times n}$, $m$ pivot columns are needed if $A$'s columns span $\mathbb{R}^m$. This also states that a minimum set of $m$ vectors can span $\mathbb{R}^m$ if the vectors are linearly independent.
:::

::: {.remark}

Consider $A \in \mathbb{R}^{3\times3}$ with only two pivot positions. Obviously, the columns of $A$ do not span $\mathbb{R}^3$ and can only form a plane. But it is also mistaken to say the columns span $\mathbb{R}^2$ because the vectors are in $\mathbb{R}^3$.

```{r, message=FALSE}
# Requires: install.packages("plotly")
library(plotly)

# --- Parameters -------------------------------------------------------------
v1 <- c(1, 0, 0)         # first vector
v2 <- c(0, 1, 1)         # second vector
v3 <- c(.8, .8, .8)
L  <- 2                  # axis half-length (range [-L, L])
head_size <- 0.18        # arrowhead size (adjust to taste)

# --- Plane grid (parametric: s * v1 + t * v2) ------------------------------
s <- seq(-1.8, 1.8, length.out = 40)
t <- seq(-1.8, 1.8, length.out = 40)
g <- expand.grid(s = s, t = t)
X <- matrix(g$s * v1[1] + g$t * v2[1], nrow = length(s), ncol = length(t))
Y <- matrix(g$s * v1[2] + g$t * v2[2], nrow = length(s), ncol = length(t))
Z <- matrix(g$s * v1[3] + g$t * v2[3], nrow = length(s), ncol = length(t))

# --- Helper: arrowhead lines for a vector ending at `p` pointing in direction d ---
arrow_lines_for_tip <- function(p, d, size = head_size) {
  # produce two short segments making a "V" arrowhead perpendicular-ish to d
  # find two small orthogonal offsets
  # naive but robust construction:
  ux <- d / sqrt(sum(d^2))
  # choose an arbitrary vector not parallel to ux
  arb <- if (abs(ux[1]) < 0.9) c(1,0,0) else c(0,1,0)
  v_perp1 <- crossprod(matrix(arb,1), matrix(ux,1))  # 1x3 result (cross)
  v_perp1 <- as.numeric(v_perp1)
  if (all(abs(v_perp1) < 1e-6)) arb <- c(0,0,1); v_perp1 <- as.numeric(crossprod(matrix(arb,1), matrix(ux,1)))
  v_perp1 <- v_perp1 / sqrt(sum(v_perp1^2))
  v_perp2 <- pracma::cross(ux, v_perp1) # need pracma for cross (or implement)
  v_perp2 <- v_perp2 / sqrt(sum(v_perp2^2))
  # two small points behind tip
  base1 <- p - ux * size + v_perp1 * (size / 2)
  base2 <- p - ux * size - v_perp1 * (size / 2)
  list(
    line1 = rbind(base1, p),
    line2 = rbind(base2, p)
  )
}

# If pracma is not available, we implement cross product quickly
cross_prod <- function(a, b) c(a[2]*b[3] - a[3]*b[2],
                             a[3]*b[1] - a[1]*b[3],
                             a[1]*b[2] - a[2]*b[1])

# replacement arrowheads function that doesn't depend on extra packages:
arrow_lines_for_tip2 <- function(p, d, size = head_size) {
  ux <- d / sqrt(sum(d^2))
  arb <- if (abs(ux[1]) < 0.9) c(1,0,0) else c(0,1,0)
  v_perp1 <- cross_prod(arb, ux)
  if (sqrt(sum(v_perp1^2)) < 1e-6) { arb <- c(0,0,1); v_perp1 <- cross_prod(arb, ux) }
  v_perp1 <- v_perp1 / sqrt(sum(v_perp1^2))
  base1 <- p - ux * size + v_perp1 * (size / 2)
  base2 <- p - ux * size - v_perp1 * (size / 2)
  list(line1 = rbind(base1, p), line2 = rbind(base2, p))
}

# --- Precompute arrowheads for axes and vectors --------------------------------
# axis ends
x_tip <- c(L,0,0); y_tip <- c(0,L,0); z_tip <- c(0,0,L)
x_head <- arrow_lines_for_tip2(x_tip, c(1,0,0), size = head_size*0.9)
y_head <- arrow_lines_for_tip2(y_tip, c(0,1,0), size = head_size*0.9)
z_head <- arrow_lines_for_tip2(z_tip, c(0,0,1), size = head_size*0.9)

# vector tips
v1_tip <- v1; v2_tip <- v2; v3_tip <- v3
v1_head <- arrow_lines_for_tip2(v1_tip, v1, size = head_size*0.9)
v2_head <- arrow_lines_for_tip2(v2_tip, v2, size = head_size*0.9)
v3_head <- arrow_lines_for_tip2(v3_tip, v3, size = head_size*0.9)

# --- Build plotly figure ------------------------------------------------------
fig <- plot_ly() %>%
  # Plane as parametric surface (x,y,z matrices)
  add_surface(x = X, y = Y, z = Z,
              opacity = 0.45,
              showscale = FALSE,
              hoverinfo = "none",
              colorscale = list(c(0,1), c("lightblue","lightblue"))) %>%
  # Axes (lines through origin)
  add_trace(type = "scatter3d", mode = "lines",
            x = c(-L, L), y = c(0,0), z = c(0,0),
            line = list(color = "black", width = 4),
            showlegend = FALSE) %>%
  add_trace(type = "scatter3d", mode = "lines",
            x = c(0,0), y = c(-L, L), z = c(0,0),
            line = list(color = "black", width = 4),
            showlegend = FALSE) %>%
  add_trace(type = "scatter3d", mode = "lines",
            x = c(0,0), y = c(0,0), z = c(-L, L),
            line = list(color = "black", width = 4),
            showlegend = FALSE) %>%
  # Axis arrowheads (two short segments each)
  add_trace(type = "scatter3d", mode = "lines",
            x = c(x_head$line1[,1], NA, x_head$line2[,1]),
            y = c(x_head$line1[,2], NA, x_head$line2[,2]),
            z = c(x_head$line1[,3], NA, x_head$line2[,3]),
            line = list(color = "black", width = 4),
            showlegend = FALSE) %>%
  add_trace(type = "scatter3d", mode = "lines",
            x = c(y_head$line1[,1], NA, y_head$line2[,1]),
            y = c(y_head$line1[,2], NA, y_head$line2[,2]),
            z = c(y_head$line1[,3], NA, y_head$line2[,3]),
            line = list(color = "black", width = 4),
            showlegend = FALSE) %>%
  add_trace(type = "scatter3d", mode = "lines",
            x = c(z_head$line1[,1], NA, z_head$line2[,1]),
            y = c(z_head$line1[,2], NA, z_head$line2[,2]),
            z = c(z_head$line1[,3], NA, z_head$line2[,3]),
            line = list(color = "black", width = 4),
            showlegend = FALSE) %>%
  # Vectors (lines from origin to tip)
  add_trace(type = "scatter3d", mode = "lines+markers",
            x = c(0, v1[1]), y = c(0, v1[2]), z = c(0, v1[3]),
            line = list(color = "red", width = 6),
            marker = list(size = 2),
            name = "v1") %>%
  add_trace(type = "scatter3d", mode = "lines+markers",
            x = c(0, v2[1]), y = c(0, v2[2]), z = c(0, v2[3]),
            line = list(color = "green", width = 6),
            marker = list(size = 2),
            name = "v2") %>%
  add_trace(type = "scatter3d", mode = "lines+markers",
            x = c(0, v3[1]), y = c(0, v3[2]), z = c(0, v3[3]),
            line = list(color = "orange", width = 6),
            marker = list(size = 2),
            name = "v3") %>%
  # Vector arrowheads
  add_trace(type = "scatter3d", mode = "lines",
            x = c(v1_head$line1[,1], NA, v1_head$line2[,1]),
            y = c(v1_head$line1[,2], NA, v1_head$line2[,2]),
            z = c(v1_head$line1[,3], NA, v1_head$line2[,3]),
            line = list(color = "red", width = 6),
            showlegend = FALSE) %>%
  add_trace(type = "scatter3d", mode = "lines",
            x = c(v2_head$line1[,1], NA, v2_head$line2[,1]),
            y = c(v2_head$line1[,2], NA, v2_head$line2[,2]),
            z = c(v2_head$line1[,3], NA, v2_head$line2[,3]),
            line = list(color = "green", width = 6),
            showlegend = FALSE) %>%
  add_trace(type = "scatter3d", mode = "lines",
            x = c(v3_head$line1[,1], NA, v3_head$line2[,1]),
            y = c(v3_head$line1[,2], NA, v3_head$line2[,2]),
            z = c(v3_head$line1[,3], NA, v3_head$line2[,3]),
            line = list(color = "orange", width = 6),
            showlegend = FALSE) %>%
  # origin marker and labels
  add_markers(x = 0, y = 0, z = 0, marker = list(size = 4, color = "black"), showlegend = FALSE) %>%
  layout(scene = list(
    aspectmode = "cube",   # equal scale on axes
    xaxis = list(title = "X", range = c(-L, L),
                 showgrid = TRUE, zeroline = FALSE, showbackground = FALSE),
    yaxis = list(title = "Y", range = c(-L, L),
                 showgrid = TRUE, zeroline = FALSE, showbackground = FALSE),
    zaxis = list(title = "Z", range = c(-L, L),
                 showgrid = TRUE, zeroline = FALSE, showbackground = FALSE),
    camera = list(eye = list(x = 0.5, y = -1.5, z = 0.7))
  ))

fig

```
:::

## Random Thoughts About the Characterization ([@thm-thm1-7-7])

::: {.remark}

The textbook warns that [@thm-thm1-7-7] does not guarantee that **every** vector in a linearly dependent set is a linear combination of the other vectors.

The simplest example of this is a zero vector. Consider a linearly independent set $S=\{\mathbf{v}_1,\dots,\mathbf{v}_n\}$. Let $S'=S \cup \{\mathbf{0}\}$, then $S'$ is a linearly dependent set (Theorem 9). Only $\mathbf{0}$ in $S'$ is a linear combination of the other vectors ($0\mathbf{v}_1+\dots+0\mathbf{v}_n$) because, for all $1 \leq k \leq n$, adding a zero vector doesn't change the span of the other vectors. Thus, $\mathbf{v}_k \notin \text{Span}\{\mathbf{v}_1,\dots,\mathbf{v}_{k-1},\mathbf{v}_{k+1},\dots,\mathbf{v}_n,\mathbf{0}\}$. Similarly, we can add, rather than a zero vector, $t\mathbf{v}_k$ to $S$, where $t \neq 0$ and $1 \leq k \leq n$. Denote this new set as $S'=S \cup \{t\mathbf{v}_k\}$. Only the newly added vector, $t\mathbf{v}_k$, and $\mathbf{v}_k$ are a linear combination of the other vectors: $t\mathbf{v}_k=t\cdot\mathbf{v}_k$ and $\mathbf{v}_k=\frac{1}{t}\cdot t\mathbf{v}_k$. Moreover, these are also the only ways by which they can be written as a linear combination of the other vectors.

Then, what if we add a linear combination of some of the vectors in $S$. Formally, let $V=\{\mathbf{v}_{i_1},\dots,\mathbf{v}_{i_m}\} \subset S$. Consider the vector $\mathbf{w}=c_1\mathbf{v}_{i_1}+\dots+c_m\mathbf{v}_{i_m}$, where $c_1 \cdots c_m \neq 0$. $S'=S \cup \{\mathbf{w}\}$ is linearly dependent. Let $V'=V \cup \{\mathbf{w}\}$. Since $\mathbf{c}$ is non-zero, for all $\mathbf{u}\in V'$, $\mathbf{u}$ can be expressed as a unique linear combination of the other vectors in $V'$. The case of the vectors not in $V'$ is the same. They cannot be written as a linear combination of the other vectors because adding a vector already in the span doesn't change the span.
:::

::: {#prp-1-7-char}

Suppose $S=\{\mathbf{v}_1,\dots,\mathbf{v}_n\}$ is an arbitrary set of vectors, where, for all $1 \leq k \leq n$, $\mathbf{v}_k\in\mathbb{R}^m$. It is always possible to partition $S$ into $p$ non-empty subsets, $V_1,\dots,V_p$, where, for every $|V_k|>1$, each vector $\mathbf{v}_i\in V_k$ is a linear combination of the other vectors in $V_k$. In addition, the partition satisfies that if a vector, $\mathbf{v}_i\in V_k$, can be written as a linear combination of the vectors other than $\mathbf{v}_i$ in $S$, it can only be written as a linear combination of the other vectors in $V_k$.  
:::